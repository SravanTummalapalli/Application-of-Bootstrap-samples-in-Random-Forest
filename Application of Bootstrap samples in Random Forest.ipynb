{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3sNKZq4XrXQh"
   },
   "source": [
    "# <font color='red'><b>Bootstrap assignment</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RAHap1Z3FZC-"
   },
   "source": [
    "<b>There will be some functions that start with the word \"grader\" ex: grader_sampples(), grader_30().. etc, you should not change those function definition.\n",
    "\n",
    "Every Grader function has to return True.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cuxBq_bvrwh2"
   },
   "source": [
    "<font color='blue'> <b>Importing packages</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m6ag91ijrQOs"
   },
   "outputs": [],
   "source": [
    "import numpy as np # importing numpy for numerical computation\n",
    "import random\n",
    "import scipy\n",
    "from sklearn.datasets import load_boston # here we are using sklearn's boston dataset\n",
    "from sklearn.metrics import mean_squared_error # importing mean_squared_error metric\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CcHOsONTt1K_"
   },
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "x=boston.data #independent variables\n",
    "y=boston.target #target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pc1htEFYuLRj",
    "outputId": "f5b60712-98b3-4cdc-b629-3546c1e3859c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "kQle3T_wuOa3",
    "outputId": "521c7bdd-5316-48d5-c534-b61d170d2c28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, 0.0000e+00, 5.3800e-01,\n",
       "        6.5750e+00, 6.5200e+01, 4.0900e+00, 1.0000e+00, 2.9600e+02,\n",
       "        1.5300e+01, 3.9690e+02, 4.9800e+00],\n",
       "       [2.7310e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
       "        6.4210e+00, 7.8900e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
       "        1.7800e+01, 3.9690e+02, 9.1400e+00],\n",
       "       [2.7290e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
       "        7.1850e+00, 6.1100e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
       "        1.7800e+01, 3.9283e+02, 4.0300e+00],\n",
       "       [3.2370e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
       "        6.9980e+00, 4.5800e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
       "        1.8700e+01, 3.9463e+02, 2.9400e+00],\n",
       "       [6.9050e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
       "        7.1470e+00, 5.4200e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
       "        1.8700e+01, 3.9690e+02, 5.3300e+00]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24. , 21.6, 34.7, 33.4, 36.2])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AEa_HqRZloH4"
   },
   "source": [
    "## <font color='red'><b>Task 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YQ5q8IxHNRk3"
   },
   "source": [
    "<font color='red'> <b>Step - 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GJCFCaOzl7Mr"
   },
   "source": [
    "*  <font color='blue'><b>Creating samples</b></font><br>\n",
    "    <b> Randomly create 30 samples from the whole boston data points</b>\n",
    "    *  Creating each sample: Consider any random 303(60% of 506) data points from whole data set and then replicate any 203 points from the sampled points\n",
    "    \n",
    "     For better understanding of this procedure lets check this examples, assume we have 10 data points [1,2,3,4,5,6,7,8,9,10], first we take 6 data points randomly , consider we have selected [4, 5, 7, 8, 9, 3] now we will replicate 4 points from [4, 5, 7, 8, 9, 3], consder they are [5, 8, 3,7] so our final sample will be [4, 5, 7, 8, 9, 3, 5, 8, 3,7]\n",
    "* <font color='blue'><b> Create 30 samples </b></font>\n",
    "    *  Note that as a part of the Bagging when you are taking the random samples <b>make sure each of the sample will have different set of columns</b><br>\n",
    "Ex: Assume we have 10 columns[1 ,2 ,3 ,4 ,5 ,6 ,7 ,8 ,9 ,10] for the first sample we will select [3, 4, 5, 9, 1, 2] and for the second sample  [7, 9, 1, 4, 5, 6, 2] and so on...\n",
    "Make sure each sample will have atleast 3 feautres/columns/attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zUqFEBSvNjCa"
   },
   "source": [
    "<font color='red'><b>Step - 2 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uqi9AhCYNq3Z"
   },
   "source": [
    "<font color='blue'><b>Building High Variance Models on each of the sample and finding train MSE value</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lLBnZHXOFln"
   },
   "source": [
    "*  Build a regression trees on each of 30 samples.\n",
    "*  Computed the predicted values of each data point(506 data points) in your corpus.\n",
    "*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{30}\\sum_{k=1}^{30}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$\n",
    "*  Now calculate the $MSE =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kls23JLnSN23"
   },
   "source": [
    "<font color='red'> <b>Step - 3 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rz2GchkGSWnh"
   },
   "source": [
    "*  <font color='blue'><b>Calculating the OOB score </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DGHkVV2kSibm"
   },
   "source": [
    "*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{k}\\sum_{\\text{k= model which was buit on samples not included } x^{i}}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$.\n",
    "*  Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RK860ocxTyoz"
   },
   "source": [
    "# <font color='red'><b>Task 2</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1dme-N6TUCrY"
   },
   "source": [
    "*  <font color='blue'><b>Computing CI of OOB Score and Train MSE</b></font>\n",
    "  *   Repeat Task 1 for 35 times, and for each iteration store the Train MSE and OOB score </li>\n",
    "<li> After this we will have 35 Train MSE values and 35 OOB scores </li>\n",
    "<li> using these 35 values (assume like a sample) find the confidence intravels of MSE and OOB Score </li>\n",
    "<li> you need to report CI of MSE and CI of OOB Score </li>\n",
    "<li> Note: Refer the Central_Limit_theorem.ipynb to check how to find the confidence intravel</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O6UcH1x9Uwrj"
   },
   "source": [
    "# <font color='red'><b>Task 3</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bOC_AgsLU7OH"
   },
   "source": [
    "*  <font color='blue'><b>Given a single query point predict the price of house.</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HYs5jSFdVILe"
   },
   "source": [
    "Consider xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60] \n",
    "Predict the house price for this point as mentioned in the step 2 of Task 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_6gxZEsFWm-8"
   },
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V2fHTdS_zpgG"
   },
   "source": [
    "# <font color='blue'> <b>Task - 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e0yGBuryOwHz"
   },
   "source": [
    "<font color='blue'><b>Step - 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lJXX8vf3z073"
   },
   "source": [
    "*  <font color='blue'> <b>Creating samples</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CSVaWG1F4uCZ"
   },
   "source": [
    "<font color='Orange'><b>Algorithm</b></font>\n",
    "\n",
    "![alt text](https://i.imgur.com/BTVYXQ1.jpg/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f_oWoN97BhDY"
   },
   "source": [
    "*  <font color='blue'><b> Write code for generating samples</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_samples(input_data, target_data):\n",
    "    \n",
    "    '''In this function, we will write code for generating 30 samples'''\n",
    "    # you can use random.choice to generate random indices without replacement\n",
    "    # Please have a look at this link https://docs.scipy.org/doc/numpy-1.16.0/reference/generated/numpy.random.choice.html for more details\n",
    "    # Please follow above pseudo code for generating samples \n",
    "\n",
    "    # return sampled_input_data , sampled_target_data,selected_rows,selected_columns\n",
    "    # note please return as lists\n",
    "    selecting_rows = np.random.choice(len(input_data), 303, replace=False)\n",
    "    replacing_rows = np.random.choice(selecting_rows, 203, replace=False)\n",
    "    number_of_columns_to_select = random.randint(3, 13)\n",
    "    selecting_columns = np.array(random.sample(range(0, 13), number_of_columns_to_select ))\n",
    "    sample_data = input_data[selecting_rows[:, None], selecting_columns]\n",
    "    target_of_sample_data = target_data[selecting_rows]\n",
    "    \n",
    "    #replicating data\n",
    "    replicated_sample_data = input_data[replacing_rows[:, None], selecting_columns]\n",
    "    target_of_replicated_sample_data = target_data[replacing_rows]\n",
    "    \n",
    "    #concatenating data\n",
    "    final_sample_data = np.vstack((sample_data, replicated_sample_data ))\n",
    "    final_target_data = np.vstack((target_of_sample_data.reshape(-1, 1), target_of_replicated_sample_data.reshape(-1, 1)))\n",
    "    \n",
    "    return final_sample_data, final_target_data, selecting_rows, selecting_columns\n",
    "  # random.choice to generate random indices without replacement\n",
    "  # selecting 303 random row indices from the input_data, without replacement\n",
    "  # now we will replicate 203 points from above selected rows\n",
    "  # Replacing Rows => Extracting 206 reandom row indices from the abvoe rows_selected\n",
    "  # Now get 3 to 13 random column indices from input_data\n",
    "  # Now Replication of Data for 203 data points out of 303 selected points\n",
    "  # Concatenating data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MivEQFlm7iOg"
   },
   "source": [
    "<font color='cyan'> <b> Grader function - 1 </b> </fongt>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AVvuhNzm7uld"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_samples(a,b,c,d):\n",
    "        length = (len(a)==506  and len(b)==506)\n",
    "        sampled = (len(a)-len(set([str(i) for i in a]))==203)\n",
    "        rows_length = (len(c)==303)\n",
    "        column_length= (len(d)>=3)\n",
    "        assert(length and sampled and rows_length and column_length)\n",
    "        return True\n",
    "a,b,c,d = generating_samples(x, y)\n",
    "grader_samples(a,b,c,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b4LSsmn4Jn2_"
   },
   "source": [
    "*  <font color='blue'> <b>Create 30 samples </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ec7MN6sL2BZ"
   },
   "source": [
    "![alt text](https://i.imgur.com/p8eZaWL.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XXlKWjCcBvTk"
   },
   "outputs": [],
   "source": [
    "# Use generating_samples function to create 30 samples \n",
    "# store these created samples in a list\n",
    "list_input_data =[]\n",
    "list_output_data =[]\n",
    "list_selected_row= []\n",
    "list_selected_columns=[]\n",
    "\n",
    "for i in range (0, 30):\n",
    "    a, b, c, d = generating_samples(x, y)\n",
    "    list_input_data.append(a)\n",
    "    list_output_data.append(b)\n",
    "    list_selected_row.append(c)\n",
    "    list_selected_columns.append(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MXUz9VFiMQkh"
   },
   "source": [
    "<font color='cyan'> <b>Grader function - 2 </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hCvIq8NuMWOC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_30(a):\n",
    "    assert(len(a)==30 and len(a[0])==506)\n",
    "    return True\n",
    "grader_30(list_input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Pv-mkZkO6dh"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "whaHCPB0O8qF"
   },
   "source": [
    "<font color='red'><b>Step - 2 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XBy4zXSWPtU8"
   },
   "source": [
    "<font color='orange'><b>Flowchart for building tree</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5xvH06HPQBdP"
   },
   "source": [
    "![alt text](https://i.imgur.com/pcXfSmp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WRwPO_uHQjul"
   },
   "source": [
    "*  <font color='blue'><b> Write code for building regression trees</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YWQp6tRwMthq"
   },
   "outputs": [],
   "source": [
    "list_of_all_models_decision_tree = []\n",
    "for i in range(0, 30):\n",
    "    model_i = DecisionTreeRegressor(max_depth=None)\n",
    "    model_i.fit(list_input_data[i], list_output_data[i])\n",
    "    list_of_all_models_decision_tree.append(model_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "21j8BKfAQ1U8"
   },
   "source": [
    "<font color='orange'><b>Flowchart for calculating MSE </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Q0mTBD2RBx_"
   },
   "source": [
    "![alt text](https://i.imgur.com/sPEE618.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6e-UamlHRjPy"
   },
   "source": [
    "After getting predicted_y for each data point, we can use sklearns mean_squared_error to calculate the MSE between predicted_y and actual_y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TnIMT7_oR312"
   },
   "source": [
    "*  <font color='blue'><b> Write code for calculating MSE</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qWhcvMRWRA9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE :  0.006551383399209485\n"
     ]
    }
   ],
   "source": [
    "array_of_Y = []\n",
    "\n",
    "for i in range(0, 30):\n",
    "    data_point_i = x[:, list_selected_columns[i]]\n",
    "    target_y_i = list_of_all_models_decision_tree[i].predict(data_point_i)\n",
    "    array_of_Y.append(target_y_i)\n",
    "  \n",
    "  \n",
    "predicted_array_of_target_y = np.array(array_of_Y)\n",
    "predicted_array_of_target_y = predicted_array_of_target_y.transpose()\n",
    "\n",
    "# print(predicted_array_of_target_y.shape)\n",
    "\n",
    "# Now to calculate MSE, first calculate the Median of Predicted Y\n",
    "# passing axis=1 will make sure the medians are computed along axis=1\n",
    "median_predicted_y = np.median(predicted_array_of_target_y, axis=1)\n",
    "median_predicted_y.shape\n",
    "\n",
    "print(\"MSE : \", mean_squared_error(y, median_predicted_y ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RuclPDMnSz8F"
   },
   "source": [
    "<font color='blue'><b>Step - 3 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ESb9FSIDTM5V"
   },
   "source": [
    "<font color='orange'><b>Flowchart for calculating OOB score</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HB-d6NMETbd9"
   },
   "source": [
    "![alt text](https://i.imgur.com/95S5Mtm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WW3GOcFzTqbt"
   },
   "source": [
    "Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zBqcS03pUYSZ"
   },
   "source": [
    "*  <font color='blue'><b> Write code for calculating OOB score </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_oob_score is 14.850484189723307\n"
     ]
    }
   ],
   "source": [
    "y_predicted_oob_median_list=[]\n",
    "for i in range(0,506):\n",
    "    \n",
    "    indicies_for_oob_models=[]\n",
    "    for index_oob in range(0,30):\n",
    "        if i not in list_selected_row[index_oob]:\n",
    "            indicies_for_oob_models.append(index_oob)\n",
    "    y_predicted_oob_list = []\n",
    "    for oob_model_index in indicies_for_oob_models:\n",
    "        model_oob=list_of_all_models_decision_tree[oob_model_index]\n",
    "        row_oob=x[i]\n",
    "        x_oob_data_point=[row_oob[columns] for columns in list_selected_columns[oob_model_index]]\n",
    "        x_oob_data_point=np.array(x_oob_data_point).reshape(1,-1)\n",
    "        y_predicted_oob_data_point=model_oob.predict(x_oob_data_point)\n",
    "        y_predicted_oob_list.append(y_predicted_oob_data_point)\n",
    "    y_predicted_oob_list=np.array(y_predicted_oob_list)\n",
    "    y_predicted_median=np.median(y_predicted_oob_list)\n",
    "    y_predicted_oob_median_list.append(y_predicted_median)\n",
    "\n",
    "def caluclate_oob_score(num_rows):\n",
    "    oob_score=0\n",
    "    for i in range(0,num_rows):\n",
    "        oob_score+=((y[i]-y_predicted_oob_median_list[i])**2)\n",
    "    final_oob_score=oob_score/506\n",
    "    return final_oob_score\n",
    "print(\"final_oob_score is\",caluclate_oob_score(506))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sbuiwX3OUjUI"
   },
   "source": [
    "# <font color='blue'><b>Task 2</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.05208027744290138, 15.425342186186965)\n"
     ]
    }
   ],
   "source": [
    "def bootstrapping_and_oob(x, y):\n",
    "\n",
    "  # Use generating_samples function to create 30 samples \n",
    "  # store these created samples in a list\n",
    "    list_input_data =[]\n",
    "    list_output_data =[]\n",
    "    list_selected_row= []\n",
    "    list_selected_columns=[]\n",
    "  \n",
    "    for i in range (0, 30):\n",
    "        a, b, c, d = generating_samples(x, y)\n",
    "        list_input_data.append(a)\n",
    "        list_output_data.append(b)\n",
    "        list_selected_row.append(c)\n",
    "        list_selected_columns.append(d)\n",
    "  \n",
    "  # building regression trees\n",
    "    list_of_all_models_decision_tree = []\n",
    "    for i in range(0, 30):\n",
    "        model_i = DecisionTreeRegressor(max_depth=None)\n",
    "        model_i.fit(list_input_data[i], list_output_data[i])\n",
    "        list_of_all_models_decision_tree.append(model_i)\n",
    "  \n",
    "  # calculating MSE\n",
    "    array_of_Y = []\n",
    "\n",
    "    for i in range(0, 30):\n",
    "        data_point_i = x[:, list_selected_columns[i]]\n",
    "        target_y_i = list_of_all_models_decision_tree[i].predict(data_point_i)\n",
    "        array_of_Y.append(target_y_i)\n",
    "    \n",
    "    \n",
    "    predicted_array_of_target_y = np.array(array_of_Y)\n",
    "    predicted_array_of_target_y = predicted_array_of_target_y.transpose()\n",
    "\n",
    "  # print(predicted_array_of_target_y.shape)\n",
    "\n",
    "  # Now to calculate MSE, first calculate the Median of Predicted Y\n",
    "  # passing axis=1 will make sure the medians are computed along axis=1\n",
    "    median_predicted_y = np.median(predicted_array_of_target_y, axis=1)\n",
    "  \n",
    "  # And now the final MSE\n",
    "    MSE = mean_squared_error(y, median_predicted_y )\n",
    "  \n",
    "  # Calculating OOB Score\n",
    "    y_predicted_oob_median_list = []\n",
    "\n",
    "    for i in range(0, 506):\n",
    "        indices_for_oob_models = []\n",
    "    \n",
    "    # For each of i-th row I shall build a list of sample size 30\n",
    "    # ONLY condition being that this ith row should not be part of\n",
    "    # the list_selected_row\n",
    "        for index_oob in range(0, 30):\n",
    "            if i not in list_selected_row[index_oob]:\n",
    "                indices_for_oob_models.append(index_oob)\n",
    "        \n",
    "        y_predicted_oob_list = []\n",
    "    \n",
    "        for oob_model_index in indices_for_oob_models:\n",
    "            model_oob = list_of_all_models_decision_tree[oob_model_index]\n",
    "      \n",
    "            row_oob = x[i]\n",
    "      # print('oob_model_index ', oob_model_index)\n",
    "      \n",
    "            x_oob_data_point = [row_oob[col] for col in list_selected_columns[oob_model_index] ]\n",
    "      # print('np.array(x_oob_data_point) ', np.array(x_oob_data_point))\n",
    "            x_oob_data_point = np.array(x_oob_data_point).reshape(1, -1)\n",
    "      \n",
    "            y_predicted_oob_data_point = model_oob.predict(x_oob_data_point)\n",
    "            y_predicted_oob_list.append(y_predicted_oob_data_point)\n",
    "      # \n",
    "        y_predicted_oob_list = np.array(y_predicted_oob_list)\n",
    "    \n",
    "        y_predicted_median = np.median(y_predicted_oob_list)\n",
    "        y_predicted_oob_median_list.append(y_predicted_median)\n",
    "    \n",
    "\n",
    "    oob_score = 0\n",
    "\n",
    "    for i in range(0, 506):\n",
    "        oob_score += (y[i] - y_predicted_oob_median_list[i] ) ** 2\n",
    "    # oob_score = (oob_score + (y[i] - y_predicted_oob_median_list[i] ) ** 2)\n",
    "    # 13.828377285079045\n",
    "        \n",
    "\n",
    "    final_oob_score = oob_score/506\n",
    "  \n",
    "    return MSE, final_oob_score\n",
    "\n",
    "print(bootstrapping_and_oob(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence_interval_mse_35  (0.07776336237970008, 0.13612551351201704)\n",
      "confidence_interval_oob_score_35  (13.298451267890044, 14.702814615706075)\n"
     ]
    }
   ],
   "source": [
    "x=boston.data #independent variables\n",
    "y=boston.target #target variable\n",
    "\n",
    "mse_boston_35_times_arr = []\n",
    "oob_score_boston_35_times_arr = []\n",
    "\n",
    "# Repeat Task 1 for 35 times, and for each iteration store the Train MSE and OOB score\n",
    "for i in range(0, 35):\n",
    "    mse, oob_score = bootstrapping_and_oob(x, y)\n",
    "    mse_boston_35_times_arr.append(mse)\n",
    "    oob_score_boston_35_times_arr.append(oob_score)\n",
    "\n",
    "mse_boston_35_times_arr = np.array(mse_boston_35_times_arr)\n",
    "oob_score_boston_35_times_arr = np.array(oob_score_boston_35_times_arr)\n",
    "\n",
    "confidence_level = 0.95\n",
    "degrees_of_freedom = 34 # sample.size - 1\n",
    "\n",
    "mean_of_sample_mse_35 = np.mean(mse_boston_35_times_arr)\n",
    "standard_error_of_sample_mse_35 = scipy.stats.sem(mse_boston_35_times_arr)\n",
    "\n",
    "\n",
    "# Per document - https://www.kite.com/python/answers/how-to-compute-the-confidence-interval-of-a-sample-statistic-in-python\n",
    "# confidence_interval = scipy.stats.t.interval(confidence_level, degrees_freedom, sample_mean, sample_standard_error)\n",
    "confidence_interval_mse_35 = scipy.stats.t.interval(confidence_level, degrees_of_freedom, mean_of_sample_mse_35, standard_error_of_sample_mse_35 )\n",
    "print(\"confidence_interval_mse_35 \", confidence_interval_mse_35)\n",
    "\n",
    "# Now calculate confidence inter for oob score\n",
    "mean_of_sample_oob_score_35 = np.mean(oob_score_boston_35_times_arr)\n",
    "standard_error_of_sample_oob_score_35 = scipy.stats.sem(oob_score_boston_35_times_arr)\n",
    "\n",
    "confidence_interval_oob_score_35 = scipy.stats.t.interval(confidence_level, degrees_of_freedom, mean_of_sample_oob_score_35, standard_error_of_sample_oob_score_35 )\n",
    "print(\"confidence_interval_oob_score_35 \", confidence_interval_oob_score_35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jKTnJdiBVS_e"
   },
   "source": [
    "# <font color='blue'><b>Task 3</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eXxrvZqHV1Fr"
   },
   "source": [
    "<font color='orange'><b>Flowchart for Task 3</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NyjwEJ62V6a6"
   },
   "source": [
    "<b>Hint: </b> We created 30 models by using 30 samples in TASK-1. Here, we need send query point \"xq\"  to 30 models and perform the regression on the output generated by 30 models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0emSwLL7VurD"
   },
   "source": [
    "![alt text](https://i.imgur.com/Y5cNhQk.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "29hjwKlWWDfo"
   },
   "source": [
    "*  <font color='blue'><b> Write code for TASK 3 </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i_pUlSD-VYD1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.5"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_y_given_x(x_query):\n",
    "    y_predicted_array_30_sample = []\n",
    "\n",
    "    for i in range(0, 30):\n",
    "        model_i = list_of_all_models_decision_tree[i]\n",
    "    # Extract x for ith data point with specific number of featues from list_selected_columns\n",
    "        x_data_point_i = [x_query[column] for column in list_selected_columns[i]]\n",
    "        x_data_point_i = np.array(x_data_point_i).reshape(1, -1)\n",
    "        y_predicted_i = model_i.predict(x_data_point_i)\n",
    "        y_predicted_array_30_sample.append(y_predicted_i)\n",
    "\n",
    "    y_predicted_array_30_sample = np.array(y_predicted_array_30_sample)\n",
    "    y_predicted_median = np.median(y_predicted_array_30_sample)\n",
    "    return y_predicted_median\n",
    "\n",
    "xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60]\n",
    "y_predicted_for_xq = predict_y_given_x(xq)\n",
    "y_predicted_for_xq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IOdUi-0xWOJ9"
   },
   "source": [
    "<font color='red'><b>Write observations for task 1, task 2, task 3 indetail</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By definition we know the interpretation of a 95% confidence interval for the populace mean as - If rehashed random samples  were taken and the 95% confidence interval was figured for each example, 95% of the intervals  would contain the population mean.\n",
    "\n",
    "MSE - \n",
    "There is a 95% chance that the confidence interval of (0.07776336237970008, 0.13612551351201704) contains the true population mean of MSE.\n",
    "\n",
    "OOB Score - \n",
    "There is a 95% chance that the confidence interval of (13.298451267890044, 14.702814615706075) contains the true population mean of OOB Score.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Bootstrap_assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
